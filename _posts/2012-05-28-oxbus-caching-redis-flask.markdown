---
layout: post
title: Oxbus - caching with redis in Flask
date: 2012-07-08T15:00:00.1Z
---

How embarrassing. I meant to follow up my post about [scraping live bus time information for Oxford](2012/04/02/oxbus/) sooner than this, but life got in the way. Today I'm going to talk about caching.

I can get bus times for nearby stops by scraping the Oxontime website. It works. The information is present. But isn't fast. Every stop needs another request, and those requests can be pretty slow to fulfill (particularly if you're making lots of them together). You can end up waiting for more seconds than I really like to get your responses back. It isn't computationally expensive or anything, but it is tiring and lame.

So what do we do when we don't want to generate/calculate data multiple times? We cache it!

There are lots of easy ways to cache things, especially if the object-to-be-cached is just the HTML generated by your code. On a site with a finite number of URLs where the same URL is requested a number of times, this is a tremendous option. Just cache the page.

It isn't an option for OxBus, because the main route into the site is by finding nearby stops. I like to be reasonably accurate, so the URL for your list of stops is your latitude/longitude. There are quite a few latitudes and longitudes you could be at, so caching this isn't much good.

But there is another way. In the case of this site, it's really just waiting to get the data back that takes time - everything else is pretty quick. And although every request is from a different lat/long, a large range of areas can all require the same stop. Not only that, but if you look at the stop list, then look at an individual stop, much of the data we need for the stop, we already got for the list.

### How it works

Everytime someone requests information about a stop, I check if I have the info in redis. If I don't, I retrieve it from the scraper and then put it into redis. Here's how it goes in:

I use the 'ATCO' value for the stop as the key to a redis list. Then, I work through all of the buses in my list of buses for that stop. For each one, I increment an integer key, and use it to store three values like so:

    r.set('bus:%d:service' % (k), bus['service'])
    r.set('bus:%d:destination' % (k), bus['destination'])
    r.set('bus:%d:minutes_to_departure' % (k), bus['minutes_to_departure'])

Now that Redis supports hashes this isn't so necessary, but it doesn't really matter that much.

Then, I push k into the ATCO-keyed list. Once I've done that, I set the ATCO list to expire in 60 seconds (because after 60 seconds the information is stale).

To retrieve the stops, I check if the stops's 'ATCO' value is in redis as the key to a list. If it is, I have the info. I then work through the key's in that list, looking up all the info about each bus and adding it to the list of buses for the stop. Because the key increments, I know that I can get them out in the same order I put them in.

This is simple and easy. It's not super useful, because the data becomes stale quickly, and because generally, this isn't a site where everyone is requesting exactly the same data (so there aren't that many cases where I can actually use the cached data). But it was pretty simple to do, it's good practice, and it's a lot of fun. I'd recommend it.
